quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}

quarkus.langchain4j.openai.chat-model.model-name=llama-3-2-3b
quarkus.langchain4j.openai.chat-model.log-requests=true
quarkus.langchain4j.openai.chat-model.log-responses=true

# If you want to use a different provider or run an LLM on your local machine,
# uncomment this line and update the url/port accordingly.
quarkus.langchain4j.openai.base-url=https://llama-3-2-3b-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1

quarkus.langchain4j.timeout=1m